{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOfTZojGKvPRbXNGm5/8EJB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Email Phishing Detection Model"
      ],
      "metadata": {
        "id": "PmAUAX3Pk8Rn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About Dataset\n",
        "\n",
        "The Email Phishing Dataset, compiled by user Ethan Cratchley on kaggle, is a combination of two different datasets containing \"safe\" emails from The Enron Email Dataset, along with phishing and \"safe\" emails from The Phishing Email Dataset. The dataset includes features such as the number of words, unique words, stopwords, links, unique domains, email addresses, and spelling errors, along with associated labels. The purpose of this dataset is to use machine learning to train a model that would be able to detect phishing emails. Companies and corporations can use this model to identify phishing emails, preventing attacks, and protecting sensitive information and data. In addition, Cybersecurity teams can use the model to find patterns in phishing emails, allowing them to finetune and improve the model."
      ],
      "metadata": {
        "id": "MDbbPyRTwcLY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Preprocessing\n",
        "\n",
        "\n",
        "- Perform exploratory data analysis (EDA) to gain insights into the dataset's structure and distributions.\n",
        "- Handle missing values, outliers, and any inconsistencies in the data.\n",
        "- Encode categorical variables and normalize numerical features as necessary.\n",
        "- Split the dataset into training and testing sets, ensuring a proper balance of classes.\n",
        "- Discuss your applied techniques to tackle data imbalancedness if you are working on an imbalanced dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "4M-7-_ZZwlpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing initial libraries needed\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "sns.set(color_codes=True)"
      ],
      "metadata": {
        "id": "uM5rMWgBw6Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing and reading data set\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['email_phishing_data.csv']))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "cfKVK5DVyBtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape # check for size and shape of data set"
      ],
      "metadata": {
        "id": "lKWmBvcsVJgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes # check for catergorical values\n"
      ],
      "metadata": {
        "id": "MxGxuxXHWXLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.duplicated()] # check for duplicated rows"
      ],
      "metadata": {
        "id": "xFDxWn9mWZZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum() # check for missing values"
      ],
      "metadata": {
        "id": "xdU9U275W8-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe() # check for statistical values"
      ],
      "metadata": {
        "id": "-oSvtFmBXcvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing columns to find outliers\n",
        "numeric_cols = df.select_dtypes(include='number').columns.drop('label')\n",
        "\n",
        "n = len(numeric_cols)\n",
        "cols = 3\n",
        "rows = (n + cols - 1) // cols\n",
        "\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(cols*5, rows*4))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# box plot for every feature\n",
        "for i, col in enumerate(numeric_cols):\n",
        "    sns.boxplot(y=df[col], ax=axes[i])\n",
        "    axes[i].set_title(col)\n",
        "\n",
        "# delete extra box plots\n",
        "for j in range(i+1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "qJHdy6XJYP1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scanning all frames of phishing emails ('label' = 1)\n",
        "df[df['label'] == 1]"
      ],
      "metadata": {
        "id": "b2zVNVa8yywS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization of column by 'label' to check for correlation of outliers and phishing emails\n",
        "n = len(numeric_cols)\n",
        "cols = 3\n",
        "rows = (n + cols - 1) // cols\n",
        "\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(cols*5, rows*4))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# box plot for every feature\n",
        "for i, col in enumerate(numeric_cols):\n",
        "    sns.boxplot(x='label', y=col, data=df, ax=axes[i])\n",
        "    axes[i].set_title(col)\n",
        "\n",
        "# delete extra box plots\n",
        "for j in range(i+1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "XaBPqcFh6VUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# outlier detection using z-score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "z_scores =df[numeric_cols].apply(zscore)\n",
        "\n",
        "outliers_zscore = df[(z_scores.abs() > 3).any(axis=1)]"
      ],
      "metadata": {
        "id": "doPlLbZV7llE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imputation of outliers using 'capping'\n",
        "for col in numeric_cols:\n",
        "    upper_cap = df[col].quantile(0.99)\n",
        "    lower_cap = df[col].quantile(0.01)\n",
        "    df[col] = df[col].clip(lower=lower_cap, upper=upper_cap)"
      ],
      "metadata": {
        "id": "d3YlWzi3Gc5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing columns to find outliers\n",
        "numeric_cols = df.select_dtypes(include='number').columns.drop('label')\n",
        "\n",
        "n = len(numeric_cols)\n",
        "cols = 3\n",
        "rows = (n + cols - 1) // cols\n",
        "\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(cols*5, rows*4))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# box plot for every feature\n",
        "for i, col in enumerate(numeric_cols):\n",
        "    sns.boxplot(y=df[col], ax=axes[i])\n",
        "    axes[i].set_title(col)\n",
        "\n",
        "# delete extra box plots\n",
        "for j in range(i+1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G4R1FXwNHBb6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}